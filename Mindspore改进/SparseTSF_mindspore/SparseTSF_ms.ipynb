{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc327a6-c190-40b1-99dd-36dcab00da3a",
   "metadata": {},
   "source": [
    "## 加载数据集\n",
    "设定参数在这里修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d5b4b-f396-4530-9005-58e917818448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #导入numpy工具包\n",
    "data_path = 'dataset/etth1.csv' #数据文件路径\n",
    "dataset_name = 'etth1'\n",
    "enc_in = 7 #特征数\n",
    "seq_len = 720\n",
    "pred_len = [96,192,336,720] #预测的时间步数\n",
    "period_len = 24 # 周期\n",
    "train_epochs = 30\n",
    "patience = 5\n",
    "batch_size = 256\n",
    "learning_rate = 0.02\n",
    "model_type = 'linear'\n",
    "raw_data = np.loadtxt(data_path, delimiter=',', skiprows=1, usecols=range(1,enc_in+1)) #读取数据（忽略第1行的标题及第1列的时间戳）\n",
    "print('数据形状：{0}，元素类型：{1}'.format(raw_data.shape, raw_data.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce6cf8-8adb-49df-8b0b-6980a94508c1",
   "metadata": {},
   "source": [
    "## 将输入数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3088679-61e4-4d9f-b6f1-4fd0da995058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 标准化 data\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(raw_data)  # 标准化后的数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad242a-584d-4048-98fb-699974c76ca9",
   "metadata": {},
   "source": [
    "## 生成模型输入与输出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763e24d-aec0-43af-b461-4825fec47460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(data, seq_len, pred_len, enc_in):#定义generateData函数\n",
    "    point_num = data.shape[0] #时间点总数\n",
    "    sample_num = point_num-seq_len-pred_len+1 #生成的总样本数\n",
    "    X = np.zeros((sample_num, seq_len, enc_in)) #用于保存输入数据\n",
    "    Y = np.zeros((sample_num, pred_len, enc_in)) #用于保存对应的输出数据\n",
    "    for i in range(sample_num): #通过遍历逐一生成输入数据和对应的输出数据\n",
    "        X[i] = data[i:i+seq_len] #前seq_len个时间点数据组成输入数据\n",
    "        Y[i] = data[i+seq_len:i+seq_len+pred_len]#后pred_len个时间点数据组成输出数据\n",
    "    return X, Y #返回所生成的模型的输入数据X和输出数据Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea0f17-3997-4479-9c6c-23b4da7b66a5",
   "metadata": {},
   "source": [
    "## 生成各个预测长度对应的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8993d12-79e7-401d-b796-da4c89d6bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_datasets = []\n",
    "Y_datasets = []\n",
    "# sub_data = data[:1000,:] # 数据集太大的切割\n",
    "for i in range(len(pred_len)):\n",
    "    X_i, Y_i = generateData(data, seq_len, pred_len[i], enc_in) #生成任务1所用的数据集\n",
    "    X_datasets.append(X_i)\n",
    "    Y_datasets.append(Y_i)\n",
    "    print('任务{0}数据集输入数据形状：{1}，输出数据形状：{2}'.format(i+1,X_i.shape, Y_i.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0ce3a0-819d-4cd3-a0f6-c7519955b745",
   "metadata": {},
   "source": [
    "## 划分训练集、验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23994ba6-39fd-459a-bfce-78acf065432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, Y): #定义splitData函数\n",
    "    N = X.shape[0] #样本总数\n",
    "    train_X,train_Y=X[:int(N*0.6)],Y[:int(N*0.6)] #前60%的数据作为训练集\n",
    "    vali_X,vali_Y=X[int(N*0.6):int(N*0.8)],Y[int(N*0.6):int(N*0.8)] #中间20%的数据作为验证集\n",
    "    test_X,test_Y=X[int(N*0.8):],Y[int(N*0.8):] #最后20%的数据作为测试集\n",
    "    return train_X,train_Y, vali_X,vali_Y, test_X,test_Y#返回划分好的数据集\n",
    "\n",
    "train_X_datasets = []\n",
    "train_Y_datasets = []\n",
    "vali_X_datasets = []\n",
    "vali_Y_datasets = []\n",
    "test_X_datasets = []\n",
    "test_Y_datasets = []\n",
    "\n",
    "for i in range(len(pred_len)):\n",
    "    train_X_i, train_Y_i, vali_X_i, vali_Y_i, test_X_i, test_Y_i=splitData(X_datasets[i], Y_datasets[i])\n",
    "    train_X_datasets.append(train_X_i)\n",
    "    train_Y_datasets.append(train_Y_i)\n",
    "    vali_X_datasets.append(vali_X_i)\n",
    "    vali_Y_datasets.append(vali_Y_i)\n",
    "    test_X_datasets.append(test_X_i)\n",
    "    test_Y_datasets.append(test_Y_i)\n",
    "    print('任务{0}训练集样本数：{1}，验证集样本数：{2}，测试集样本数：{3}'.format(i+1,train_X_i.shape[0], vali_X_i.shape[0], test_X_i.shape[0])) #输出任务i训练集、验证集和测试集的样本数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852dc02-91c2-4ae4-b2d3-23530e919cde",
   "metadata": {},
   "source": [
    "## 定义数据序列类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f5da2-04fc-4a7c-b1cf-c26ef4a4a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTimeSeriesDataset(): #定义MultiTimeSeriesDataset类\n",
    "    def __init__(self, X, Y): #构造方法\n",
    "        self.X, self.Y = X, Y #设置输入数据和输出数据\n",
    "    def __len__(self):\n",
    "        return len(self.X) #获取数据的长度\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index] #根据索引值为index的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb7242d-4ca5-48f4-ba15-085414704eab",
   "metadata": {},
   "source": [
    "## 生成MindSpore数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84110021-a43b-49d9-a247-cf5bc15eb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import Tensor #导入Tensor类\n",
    "from mindspore.dataset import GeneratorDataset #导入GeneratorDataset类\n",
    "def generateMindsporeDataset(X, Y, batch_size): #定义generateMindsporeDataset函数\n",
    "    dataset = MultiTimeSeriesDataset(X.astype(np.float32), Y.astype(np.float32)) #根据X和Y创建MultiTimeSeriesDataset类对象\n",
    "    dataset = GeneratorDataset(dataset, column_names=['data','label']) #创建GeneratorDataset类对象，并指定数据集两列的列名称分别是data和label\n",
    "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=False) #将数据集分成多个批次，以支持批量训练\n",
    "    return dataset #返回可用于模型训练和测试的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f2aed-49bb-48f7-8687-29e8484f912e",
   "metadata": {},
   "source": [
    "## 定义config类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f5529-303d-4c84-af7c-f04310c7025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs:\n",
    "    def __init__(\n",
    "        self, \n",
    "        seq_len=720, \n",
    "        pred_len=96, \n",
    "        enc_in=7, \n",
    "        period_len=24, \n",
    "        train_epochs = 30,\n",
    "        patience = 5,\n",
    "        learning_rate = 0.02,\n",
    "        dataset_name = 'unknown',\n",
    "        model_type='linear',\n",
    "        d_model=64\n",
    "    ):\n",
    "        \"\"\"\n",
    "        初始化配置参数\n",
    "        :param seq_len: 输入序列长度\n",
    "        :param pred_len: 预测序列长度\n",
    "        :param enc_in: 特征维度数\n",
    "        :param period_len: 周期长度\n",
    "        :param d_model: MLP的隐藏层维度\n",
    "        :param model_type: 模型类型（'linear' 或 'mlp'）\n",
    "        \"\"\"\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_in = enc_in\n",
    "        self.period_len = period_len\n",
    "        self.train_epochs = train_epochs\n",
    "        self.patience = patience\n",
    "        self.learning_rate = learning_rate\n",
    "        self.d_model = d_model\n",
    "        self.model_type = model_type\n",
    "        self.dataset_name = dataset_name\n",
    "        \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"Configs(seq_len={self.seq_len}, pred_len={self.pred_len}, \"\n",
    "            f\"enc_in={self.enc_in}, period_len={self.period_len}, \"\n",
    "            f\"train_epochs={self.train_epochs}, patience={self.patience}, flearning_rate={self.learning_rate}, \"\n",
    "            f\"dataset_name={self.dataset_name},model_type='{self.model_type}')\"\n",
    "        )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aaf998-36c4-4a06-b8c4-f13a574d6397",
   "metadata": {},
   "source": [
    "## 定义SparseTSF类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd31d7-8303-4f2d-93a1-61584cef8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "from mindspore import nn, ops\n",
    "\n",
    "class SparseTSF(nn.Cell):  # 定义 SparseTSF 类\n",
    "    def __init__(self, configs):\n",
    "        super(SparseTSF, self).__init__()\n",
    "        print(configs)\n",
    "        # 获取参数\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.enc_in = configs.enc_in\n",
    "        self.period_len = configs.period_len\n",
    "        self.patience = configs.patience\n",
    "        self.d_model = configs.d_model\n",
    "        self.model_type = configs.model_type\n",
    "        self.dataset_name = configs.dataset_name\n",
    "        assert self.model_type in ['linear', 'mlp']\n",
    "\n",
    "        self.seg_num_x = self.seq_len // self.period_len\n",
    "        self.seg_num_y = self.pred_len // self.period_len\n",
    "\n",
    "        # 1D卷积层，用于时间序列局部特征提取\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=1 + 2 * (self.period_len // 2),\n",
    "            stride=1,\n",
    "            pad_mode='pad',\n",
    "            padding=self.period_len // 2,\n",
    "            has_bias=False\n",
    "        )\n",
    "\n",
    "        # 稀疏预测层，支持linear和mlp两种类型\n",
    "        if self.model_type == 'linear':\n",
    "            self.linear = nn.Dense(self.seg_num_x, self.seg_num_y, has_bias=False)\n",
    "        elif self.model_type == 'mlp':\n",
    "            self.mlp = nn.SequentialCell(\n",
    "                nn.Dense(self.seg_num_x, self.d_model),\n",
    "                nn.ReLU(),\n",
    "                nn.Dense(self.d_model, self.seg_num_y)\n",
    "            )\n",
    "\n",
    "    def construct(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # 归一化并调整维度：b, s, c -> b, c, s\n",
    "        seq_mean = ops.mean(x, 1, keep_dims=True)\n",
    "        # seq_std = ops.std(x,1,0,keepdims=True)\n",
    "        \n",
    "        # print(x.shape, seq_mean.shape, seq_std.shape)\n",
    "        #x = ops.permute((x - seq_mean)/seq_std, (0,2,1))\n",
    "        x = ops.permute((x - seq_mean), (0,2,1))\n",
    "        # 1D卷积聚合局部特征\n",
    "        x = self.conv1d(x.reshape(-1, 1, self.seq_len)).reshape(-1, self.enc_in, self.seq_len) + x\n",
    "        # 降采样：b, c, s -> bc, n, w -> bc, w, n\n",
    "        x = ops.permute(x.reshape(-1, self.seg_num_x, self.period_len), (0, 2, 1))\n",
    "        # 稀疏预测\n",
    "        if self.model_type == 'linear':\n",
    "            y = self.linear(x)  # bc, w, m\n",
    "        elif self.model_type == 'mlp':\n",
    "            y = self.mlp(x)\n",
    "        # 上采样：bc, w, m -> bc, m, w -> b, c, s\n",
    "        y = ops.permute(y,(0, 2, 1)).reshape(batch_size, self.enc_in, self.pred_len)\n",
    "        \n",
    "        # 调整维度并还原均值\n",
    "        # y = ops.permute(y,(0, 2, 1)) * seq_std + seq_mean\n",
    "        y = ops.permute(y,(0, 2, 1))  + seq_mean\n",
    "        # print(\"----mark\")\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad70e73-6858-4bf6-9457-e67590c31324",
   "metadata": {},
   "source": [
    "## 学习率调整\n",
    "根据SparseTSF代码，学习率调整选择其中type3策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d9744-b533-4c88-99b9-24974c04fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_learning_rate_tensor(learning_rate, max_epoch, steps_per_epoch):\n",
    "    # 使用列表生成学习率序列，每个epoch生成steps_per_epoch个相同的学习率\n",
    "    lr_list = []\n",
    "    for epoch in range(1, max_epoch + 1):\n",
    "        if epoch < 3:\n",
    "            lr = learning_rate\n",
    "        else:\n",
    "            lr = learning_rate * (0.8 ** (epoch - 3))\n",
    "        # 为当前epoch生成steps_per_epoch个学习率\n",
    "        lr_list.extend([lr] * steps_per_epoch)\n",
    "    \n",
    "    # 转换为 MindSpore Tensor\n",
    "    lr_tensor = mindspore.Tensor(np.array(lr_list), mindspore.float32)\n",
    "    return lr_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94118f-077c-4b03-9a83-d6e78e5fec6a",
   "metadata": {},
   "source": [
    "## EarlyStopping类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c1afe-433c-4a84-84a7-05dc833790f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'早停轮次: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(f'验证损失降低 ({self.val_loss_min:.6f} --> {val_loss:.6f}).  保存模型 于{path}')\n",
    "        mindspore.save_checkpoint(model, path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d2c8f-5c83-4caf-aecb-b9eaacf2a538",
   "metadata": {},
   "source": [
    "## 定义run_exp类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ed036-cf04-4b06-b246-8aa9504290b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "from mindspore import Tensor\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SparseTSFModelRun:\n",
    "    def __init__(self, model, loss_fn, optimizer=None, grad_fn=None):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.grad_fn = grad_fn\n",
    "\n",
    "    def _train_one_step(self, data, label):\n",
    "        (loss, _), grads = self.grad_fn(data, label)\n",
    "        self.optimizer(grads)\n",
    "        return loss\n",
    "\n",
    "    def _train_one_epoch(self, train_dataset):\n",
    "        self.model.set_train(True)\n",
    "        for data, label in train_dataset.create_tuple_iterator():\n",
    "            self._train_one_step(data, label)\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        self.model.set_train(False)\n",
    "        ls_pred, ls_label = [], []\n",
    "        for data, label in dataset.create_tuple_iterator():\n",
    "            pred = self.model(data)\n",
    "            ls_pred += list(pred[:, :, -1].asnumpy())\n",
    "            ls_label += list(label[:, :, -1].asnumpy())\n",
    "        \n",
    "        preds_tensor = Tensor(ls_pred)\n",
    "        labels_tensor = Tensor(ls_label)\n",
    "        loss = self.loss_fn(preds_tensor, labels_tensor)\n",
    "        return loss.asnumpy(), np.array(ls_pred), np.array(ls_label)\n",
    "\n",
    "    def train(self, train_dataset, vali_dataset, test_dataset, max_epoch_num):\n",
    "        min_loss = np.finfo(np.float32).max\n",
    "        steps_per_epoch = train_dataset.get_dataset_size()\n",
    "        print(f\"每个 epoch 的 step 数量: {steps_per_epoch}\")\n",
    "        # 对应文件夹名\n",
    "        folder = f'{self.model.dataset_name}_{self.model.seq_len}_{self.model.pred_len}_{self.model.period_len}_{self.model.enc_in}_{self.model.model_type}'\n",
    "        ckpt_path = f'checkpoints/{folder}/checkpoint.ckpt'\n",
    "        # 如无创建\n",
    "        os.makedirs(f'checkpoints/{folder}', exist_ok=True)\n",
    "        # 配置早停\n",
    "        early_stopping = EarlyStopping(patience=self.model.patience, verbose=True)\n",
    "        print('>>>>>>>>>开始训练>>>>>>>>>')\n",
    "\n",
    "        for epoch in range(1, max_epoch_num + 1):\n",
    "            start_time = time.time()\n",
    "\n",
    "            print(f'第{epoch}/{max_epoch_num}轮')\n",
    "            print(f'当前学习率调整为：{self.optimizer.get_lr()}')\n",
    "            self._train_one_epoch(train_dataset)\n",
    "\n",
    "            train_loss, _, _ = self.evaluate(train_dataset)\n",
    "            val_loss, _, _ = self.evaluate(vali_dataset)\n",
    "            test_loss, preds, labels = self.evaluate(test_dataset)\n",
    "\n",
    "            end_time = time.time()\n",
    "            epoch_time = end_time - start_time\n",
    "\n",
    "            print(f'训练集损失: {train_loss}, 验证集损失: {val_loss}, 测试集损失: {test_loss}, 用时: {epoch_time:.2f}s')\n",
    "\n",
    "            if val_loss < min_loss:\n",
    "                mindspore.save_checkpoint(self.model, ckpt_path)\n",
    "                min_loss = val_loss\n",
    "\n",
    "            # 输出模型训练图表\n",
    "            if epoch % 10 == 1 or epoch == max_epoch_num:\n",
    "                for data0, label0 in test_dataset.create_tuple_iterator():\n",
    "                    inputs = data0[:, :, -1].asnumpy()\n",
    "                    gt = np.concatenate((inputs[0, :], labels[0, :]), axis=0)\n",
    "                    pd = np.concatenate((inputs[0, :], preds[0, :]), axis=0)\n",
    "                    break\n",
    "                self._plot_results(gt, pd, epoch,'train', folder)\n",
    "\n",
    "            # 判断早停\n",
    "            early_stopping(val_loss, self.model, ckpt_path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        print('训练完成！')\n",
    "        self.test(test_dataset, ckpt_path, folder)\n",
    "\n",
    "    def test(self, test_dataset, ckpt_path, img_folder):\n",
    "        print('>>>>>>>>>开始测试>>>>>>>>>')\n",
    "        mindspore.load_checkpoint(ckpt_path, net=self.model)\n",
    "        loss, preds, labels = self.evaluate(test_dataset)\n",
    "        print(f'测试集损失: {loss}')\n",
    "        for data0, label0 in test_dataset.create_tuple_iterator():\n",
    "            inputs = data0[:, :, -1].asnumpy()\n",
    "            gt = np.concatenate((inputs[0, :], labels[0, :]), axis=0)\n",
    "            pd = np.concatenate((inputs[0, :], preds[0, :]), axis=0)\n",
    "            break\n",
    "        self._plot_results(gt, pd, 0,'test', img_folder)\n",
    "\n",
    "    def _plot_results(self, groundtruth, prediction, identifier, runtype, folder):\n",
    "        os.makedirs(f\"{runtype}_result\", exist_ok=True)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(groundtruth, label='Ground Truth', color='blue', linewidth=2)\n",
    "        plt.plot(prediction, label='Prediction', color='orange', linewidth=2)\n",
    "        plt.title(f'Prediction vs Ground Truth - {identifier}')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        pdf_path = f\"{runtype}_result/{folder}/result_{identifier}.pdf\"\n",
    "        # 提取目标文件的目录路径\n",
    "        folder_path = os.path.dirname(pdf_path)\n",
    "        # 创建目标文件夹（如果不存在）\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        plt.savefig(pdf_path)\n",
    "        plt.close()\n",
    "        print(f'结果图已保存到 {pdf_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8111edb-adc7-4408-8997-e9673b09ce6a",
   "metadata": {},
   "source": [
    "## 开始预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0d569-9c95-4d80-9cce-f12dbdb78075",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(pred_len)):\n",
    "    print(f'-----------当前预测长度为{pred_len[index]}')\n",
    "    # 生成对应mindspore数据集\n",
    "    train_dataset_t = generateMindsporeDataset(train_X_datasets[index], train_Y_datasets[index], batch_size)\n",
    "    vali_dataset_t = generateMindsporeDataset(vali_X_datasets[index], vali_Y_datasets[index], batch_size)\n",
    "    test_dataset_t = generateMindsporeDataset(vali_X_datasets[index], vali_Y_datasets[index], batch_size)\n",
    "    for data, label in train_dataset_t.create_tuple_iterator():\n",
    "        print('数据形状：', data.shape, '，数据类型：', data.dtype)\n",
    "        print('标签形状：', label.shape, '，数据类型：', label.dtype)\n",
    "        break\n",
    "    configs = Configs(seq_len, pred_len[index], enc_in, period_len,train_epochs, patience, learning_rate, dataset_name,model_type)\n",
    "    model = SparseTSF(configs) #创建模型对象\n",
    "    loss_fn = nn.MAELoss() #定义损失函数\n",
    "    #使用Adam优化器 并且使用type3学习率调整策略\n",
    "    steps_per_epoch = train_dataset_t.get_dataset_size()\n",
    "    learning_rate_tensor = generate_learning_rate_tensor(configs.learning_rate,configs.train_epochs,steps_per_epoch)\n",
    "    optimizer = nn.Adam(model.trainable_params(), learning_rate_tensor) \n",
    "    def forward_fn(data, label): #定义前向计算的forward_fn函数\n",
    "        pred = model(data) #使用sparseTSF模型进行预测\n",
    "        loss = loss_fn(pred[:,:,:], label[:,:,:]) #根据损失函数计算损失值\n",
    "        return loss, pred #返回损失值和预测结果\n",
    "    grad_fn = mindspore.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True) #获取用于计算梯度的函数\n",
    "    model_run = SparseTSFModelRun(model, loss_fn, optimizer, grad_fn) #创建MODEL_RUN类对象model_run\n",
    "    model_run.train(train_dataset=train_dataset_t, vali_dataset=vali_dataset_t,test_dataset=test_dataset_t, max_epoch_num=configs.train_epochs) #调用model_run.train方法完成训练"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpareTSFMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
